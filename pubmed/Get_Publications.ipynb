{
 "metadata": {
  "name": "",
  "signature": "sha256:b105518243b21f3a49941f3e7be972c712c65d6de1ad3d212265c019eb877321"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "import codecs\n",
      "import json\n",
      "import string\n",
      "import pandas as pd\n",
      "from string import punctuation\n",
      "import re\n",
      "from pyUtil import easyPickle as pickle\n",
      "import unicodedata\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load Investigator Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "column_names = ['Investigator_id', \"nct_id\", 'Name', 'Investigator_Type', 'Null']\n",
      "\n",
      "investigators_df = pd.read_csv('Data/investigators.txt', names=column_names, sep=\"|\", encoding='utf-8', quoting=3)\n",
      "investigators_df = investigators_df[investigators_df.columns[:-1]]\n",
      "\n",
      "# remove everything after the comma in names to get rid of Dr. ect\n",
      "investigators_df.Name = investigators_df.Name.apply(lambda x: x.split(',')[0])\n",
      "\n",
      "#different number of unique ids to unique names\n",
      "print '# of unique facility ids: ', len(set(investigators_df.Investigator_id))\n",
      "\n",
      "print '# of unique investigator names: ', len(set(investigators_df.Name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(investigators_df.Investigator_id))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Invesigator Id actually = facility id"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get a dict of all unique investigator names associated with their ids and studies\n",
      "investigator_dict = {}\n",
      "duplicate = []\n",
      "for invest, data in investigators_df.groupby('Name'):\n",
      "#     if len(set(data.Investigator_id)) > 1:\n",
      "#         duplicate.append(data)\n",
      "    #remove Site Reference ID's\n",
      "    if 'Site Reference ID' in list(data.Name)[0]:\n",
      "        continue\n",
      "    investigator_dict[list(data.Name)[0]] = {'id': list(set(data.Investigator_id)), 'Trials':list(set(data.nct_id))}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(investigator_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "89000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "investigator_dict.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save investigator dict\n",
      "pickle.save_object(investigator_dict, 'investigator_dict.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(map(lambda x: x.lower(), investigator_dict.keys())))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#convert unicode to ascii\n",
      "# def replace_non_ascii(col):\n",
      "#     '''This function replaces unicode with the closest matching\n",
      "#     ascii character'''\n",
      "\n",
      "#     new_col = []\n",
      "#     for name in col:\n",
      "#         try:\n",
      "#             #try to replace unicode\n",
      "#             name = unicodedata.normalize('NFKD', unicode(name,\"ISO-8859-1\")).encode('ascii', 'ignore')\n",
      "#             #if it wasn't replaced remove it\n",
      "#             for letter in name:\n",
      "#                 if ord(letter) > 128:\n",
      "#                     name = name.replace(letter, '')\n",
      "#         except:\n",
      "#             pass\n",
      "#         new_col.append(name)\n",
      "#     return new_col\n",
      "\n",
      "# test = replace_non_ascii(investigator_dict.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print u'Marie-H\\xe9l\\xe8ne Girouard'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Pull publications"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#break up the list of names into 5 chuncks\n",
      "list_1 = investigator_dict.keys()[:(len(investigator_dict.keys())/5)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(list_1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_publications(name_list, list_num):\n",
      "    count=0\n",
      "    result_dict = {}\n",
      "    for name in name_list:\n",
      "        start_time = time.time()\n",
      "        #get publication ids for investigator\n",
      "        search_start = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed'\n",
      "        investigator = name\n",
      "\n",
      "        r = requests.get(search_start + '&term=%s[Author]&retmax=100000' % investigator)\n",
      "        soup = BeautifulSoup(r.text)\n",
      "        ids = [s.text for s in soup.find_all('id')]\n",
      "        \n",
      "        #don't do second call if there are no ids\n",
      "        if len(ids) == 0:\n",
      "            continue\n",
      "        \n",
      "        #get publications from ids\n",
      "        summary_start = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed'\n",
      "        id_list = ','.join(ids)\n",
      "\n",
      "        r = requests.get(summary_start + '&id=%s&retmode=xml&retmax=10000' % id_list)\n",
      "\n",
      "        #pickle does not work with soup objects\n",
      "        #soup = BeautifulSoup(r.text)\n",
      "        \n",
      "        #add publications to the dict\n",
      "        result_dict[name] = r.text\n",
      "        \n",
      "        #time taken\n",
      "        if (time.time() - start_time) < 1:\n",
      "            time.sleep(1-(time.time() - start_time))\n",
      "\n",
      "        if (count % 500) == 0:\n",
      "            pickle.save_object(result_dict, 'investigator_dict_%d.pkl' % (list_num))\n",
      "            print count\n",
      "            \n",
      "        count += 1\n",
      "\n",
      "    return result_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pub_dict_part_1 = get_publications(list_1, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "part_1 = pickle.open_object('investigator_dict_1.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(part_1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "part_1.items()[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.save_object(investigator_dict, 'investigator_dict.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "randomdict = {'name': {}}\n",
      "\n",
      "\n",
      "start_time = time.time()\n",
      "\n",
      "#get publication ids for investigator\n",
      "search_start = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed'\n",
      "investigator = u'Rodney Badger'\n",
      "\n",
      "r = requests.get(search_start + '&term=%s[Author]&retmax=100000' % investigator)\n",
      "soup = BeautifulSoup(r.text)\n",
      "ids = [s.text for s in soup.find_all('id')]\n",
      "\n",
      "#get publications from ids\n",
      "summary_start = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed'\n",
      "id_list = ','.join(ids)\n",
      "\n",
      "r = requests.get(summary_start + '&id=%s&retmode=xml&retmax=10000' % id_list)\n",
      "\n",
      "soup = BeautifulSoup(r.text)\n",
      "\n",
      "print r.text\n",
      "\n",
      "#add publications to the dict\n",
      "randomdict['name']['publication'] = soup\n",
      "\n",
      "\n",
      "print(\"--- %s seconds ---\" % (time.time() - start_time))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1.71781802177\n",
      "1.8126809597\n",
      "0.646274089813\n",
      "0.947391033173"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}