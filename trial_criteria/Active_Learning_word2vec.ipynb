{
 "metadata": {
  "name": "",
  "signature": "sha256:76d2fec3980109c91cdebca88505efd0b633a389f14e8c1b5bb2182cb99ebafa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import cPickle as pickle\n",
      "from collections import Counter\n",
      "from random import shuffle\n",
      "import word2vec\n",
      "import sqlalchemy\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.sql import select\n",
      "from string import punctuation\n",
      "import db_connect\n",
      "import uuid\n",
      "from db_criteria_tables import metadata, criteria_concept_staging, concept_predictors\n",
      "from db_criteria_tables import concept_predictors_reject, concept_terms, concept_terms_reject, criteria_tagged"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Initial Concept/Term Selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def get_syn(word):\n",
      "    indexes, metrics = model.cosine(word, n=20)\n",
      "    return model.generate_response(indexes, metrics).tolist()\n",
      "\n",
      "def human_checker_initial(term, syns, term_list, term_exc):\n",
      "    '''This function loops through the possible similar words and\n",
      "    lets human input decide if they actually are or not'''\n",
      "    print 'Are the following terms similar to your term: %r?' % (term)\n",
      "    if len(syns) > 1:\n",
      "        for syn in syns:\n",
      "            print 'Term: \\x1b[35m %s \\x1b[0m  Likelihood: \\x1b[36m %f \\x1b[0m' % (syn[0], syn[1])\n",
      "            answer_switch = True\n",
      "            while answer_switch:\n",
      "                add_term = raw_input('Is this a similar term to %s? (Y, N, exit): ' % (term))\n",
      "                if add_term.lower() == 'y':\n",
      "                    term_list.update(syn[0])\n",
      "                    answer_switch = False\n",
      "                elif add_term.lower() == 'exit':\n",
      "                    #pass switch to exit program\n",
      "                    exit_switch = False\n",
      "                    return term_list, term_exc, exit_switch\n",
      "                elif add_term.lower() == 'n':\n",
      "                    term_exc.update(syn[0])\n",
      "                    answer_switch = False\n",
      "                else:\n",
      "                    pass\n",
      "\n",
      "    exit_switch = False\n",
      "    return term_list, term_exc, exit_switch\n",
      "\n",
      "\n",
      "def choose_more_terms(model, initial_term, term_list, term_exc):\n",
      "    #get list of syns\n",
      "    syns = get_syn(initial_term)\n",
      "    #replace underscores in phrases with spaces\n",
      "    #syns = [' '.join(term.split('_')) for term in syns]\n",
      "    term_list, term_exc, exit_switch = human_checker_initial(initial_term, syns, term_list, term_exc)\n",
      "    return term_list, term_exc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#term_list, term_exc = choose_more_terms(model, initial_term, term_list, term_exc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Are the following terms similar to your term: 'drug'?\n",
        "Term: \u001b[35m medication \u001b[0m  Likelihood: \u001b[36m 0.764090 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m drugs \u001b[0m  Likelihood: \u001b[36m 0.729234 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_product \u001b[0m  Likelihood: \u001b[36m 0.686553 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m agent \u001b[0m  Likelihood: \u001b[36m 0.669450 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m test_article \u001b[0m  Likelihood: \u001b[36m 0.617005 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m imp \u001b[0m  Likelihood: \u001b[36m 0.615993 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicinal_product \u001b[0m  Likelihood: \u001b[36m 0.604440 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medications \u001b[0m  Likelihood: \u001b[36m 0.601529 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_drug \u001b[0m  Likelihood: \u001b[36m 0.584737 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m vaccine \u001b[0m  Likelihood: \u001b[36m 0.573229 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m prescription_drugs \u001b[0m  Likelihood: \u001b[36m 0.570114 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m compound \u001b[0m  Likelihood: \u001b[36m 0.560294 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m substance \u001b[0m  Likelihood: \u001b[36m 0.552736 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m otc_medications \u001b[0m  Likelihood: \u001b[36m 0.545499 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicinal_products \u001b[0m  Likelihood: \u001b[36m 0.543759 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m product \u001b[0m  Likelihood: \u001b[36m 0.543593 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicines \u001b[0m  Likelihood: \u001b[36m 0.535349 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m ip \u001b[0m  Likelihood: \u001b[36m 0.533222 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m illicit_drug \u001b[0m  Likelihood: \u001b[36m 0.528963 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_compound \u001b[0m  Likelihood: \u001b[36m 0.528536 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Pull in past predictor lists for weighting from db"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#do this here, should be a list of lists\n",
      "past_predictors = []\n",
      "def get_past_predictors(engine):\n",
      "    '''pulls all the past predictors from other concepts into a list of lists'''\n",
      "    result = engine.execute(select(concept_predictors.c.concept_id,\n",
      "                                   concept_predictors.c.predictor))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "List of noun phrases to skip"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skip_noun_phrase_list = ['month', 'months', 'patient', 'history', 'day', 'days',\n",
      "                         'year', 'years', 'week', 'weeks', 'subject', 'study']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find New Preds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def active_learn_predictors(data, term_list, pred_list, pred_exc):\n",
      "    #look for more predictors for each concept by finding sentnces that have \n",
      "    #concept terms in them and looking for predictors in those sentences \n",
      "\n",
      "    def get_pred(text, term_list, pred_exc, pred_list):\n",
      "        pred_options_dict = Counter()\n",
      "        for sent in text:\n",
      "            #if the sentance has less than 2 words skip it\n",
      "            if len(sent) <= 1:\n",
      "                continue\n",
      "            #crate a sentence rank for judging weight of terms found\n",
      "            sent_rank = 0\n",
      "            for term in term_list:\n",
      "                if term.lower() in ' '.join(zip(*sent)[0]).lower():\n",
      "                    sent_rank += 1\n",
      "            result = chunker(sent)\n",
      "            preds = [' '.join(x) for x in [[x[0] for x in term] for term in result]]\n",
      "            preds.append(' '.join([sent[0][0], sent[1][0]]))\n",
      "            #lower case all preds\n",
      "            preds = [x.lower() for x in preds]\n",
      "            preds = preds * sent_rank\n",
      "            pred_options_dict.update(preds)\n",
      "\n",
      "        #get top 20 predictors that have not been seen before\n",
      "        sorted_preds = sorted(pred_options_dict.items(), key=lambda x: x[1], reverse=True)\n",
      "        counter = 0\n",
      "        top_preds = []\n",
      "        for pred in sorted_preds:\n",
      "            if pred[0] not in pred_list and pred[0] not in pred_exc:\n",
      "                top_preds.append(pred)\n",
      "                counter += 1\n",
      "                if counter == 15 or counter == len(sorted_preds):\n",
      "                    return top_preds\n",
      "        #if there are no preds return empty list\n",
      "        return top_preds\n",
      "\n",
      "    #get chunks for preds\n",
      "    def chunker(sent):\n",
      "\n",
      "        chunk_reg1 = r\"\"\"\n",
      "                          CHUNK: {<NN.*><IN>}\n",
      "                     \"\"\"\n",
      "        chunk_reg2 = r\"\"\"\n",
      "                          CHUNK: {<VB.*><DT>}\n",
      "                     \"\"\"\n",
      "        chunk_reg3 = r\"\"\"\n",
      "                          CHUNK: {<NN.*><VB.*>}\n",
      "                     \"\"\"\n",
      "        results = []\n",
      "\n",
      "        for chunk_reg in [chunk_reg1, chunk_reg2, chunk_reg3]:\n",
      "            cp = nltk.RegexpParser(chunk_reg)\n",
      "\n",
      "            try:\n",
      "                tree = cp.parse(sent)\n",
      "            except Exception as e:\n",
      "                print e\n",
      "                print sent\n",
      "                asdfa\n",
      "            \n",
      "            for subtree in tree.subtrees():\n",
      "                if subtree.label() == 'CHUNK':\n",
      "                    results.append(subtree[:])\n",
      "        return results\n",
      "\n",
      "    def human_checker(term, pred_list, top_preds, pred_exc):\n",
      "        '''This function loops through the possible predictors and\n",
      "        lets human input decide if they actually are or not'''\n",
      "        print 'Are the following predictors of these %r?' % (term)\n",
      "        if len(top_preds) > 1:\n",
      "            for pred in top_preds:\n",
      "                print 'Predictor: \\x1b[35m %s \\x1b[0m  Count: \\x1b[36m %d \\x1b[0m' % (pred[0], pred[1])\n",
      "                answer_switch = True\n",
      "                while answer_switch:\n",
      "                    add_pred = raw_input('Is this a predictor of %s? (Y, N, exit): ' % (term[0]))\n",
      "                    if add_pred.lower() == 'y':\n",
      "                        pred_list.update(pred[0])\n",
      "                        answer_switch = False\n",
      "                    elif add_pred.lower() == 'exit':\n",
      "                        #pass switch to exit program\n",
      "                        exit_switch = False\n",
      "                        return pred_list, pred_exc, exit_switch\n",
      "                    elif add_pred.lower() == 'n':\n",
      "                        pred_exc.update(pred[0])\n",
      "                        answer_switch = False\n",
      "                    else:\n",
      "                        pass\n",
      "                    \n",
      "        exit_switch = False\n",
      "        return pred_list, pred_exc, exit_switch\n",
      "\n",
      "\n",
      "    top_preds = get_pred(data, term_list, pred_exc, pred_list)\n",
      "\n",
      "    pred_list, pred_exc, exit_switch = human_checker(term_list, pred_list, top_preds, pred_exc)\n",
      " \n",
      "    print 'Active Learning Complete'\n",
      "    return pred_list, pred_exc, exit_switch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find New Terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def active_learn_terms(data, term_list, pred_list, term_exc, past_predictors):\n",
      "    #look for more terms for each concept by finding sentnces that have \n",
      "    #predictors in them and looking for terms in those sentences \n",
      "\n",
      "    def get_term(text, term_list, term_exc, pred_list):\n",
      "        term_options_dict = Counter()\n",
      "        for sent in text:\n",
      "            #skip sentence if it contains less than one word\n",
      "            if len(sent) <= 1:\n",
      "                    continue\n",
      "            #crate a sentence rank for judging weight of terms found\n",
      "            sent_rank = 0\n",
      "            for pred in pred_list:\n",
      "                if pred[0].lower() in ' '.join(zip(*sent)[0]).lower():\n",
      "                    sent_rank += pred[1]\n",
      "            result = chunker(sent)\n",
      "            terms = [' '.join(x) for x in [[x[0] for x in term] for term in result]]\n",
      "            terms.append(' '.join([sent[0][0], sent[1][0]]))\n",
      "            #lower case all preds\n",
      "            terms = [x.lower() for x in terms]\n",
      "            #add weights to terms by multiplying by sent_rank\n",
      "            terms = terms * sent_rank\n",
      "            term_options_dict.update(terms)\n",
      "\n",
      "        #get top 20 predictors that have not been seen before\n",
      "        sorted_terms = sorted(term_options_dict.items(), key=lambda x: x[1], reverse=True)\n",
      "        counter = 0\n",
      "        top_terms = []\n",
      "        for term in sorted_terms:\n",
      "            if term[0] not in term_list and term[0] not in term_exc:\n",
      "                top_terms.append(term)\n",
      "                counter += 1\n",
      "                if counter == 15 or counter == len(sorted_terms):\n",
      "                    return top_terms\n",
      "        #if there are no preds return empty list\n",
      "        return top_terms\n",
      "\n",
      "    #get chunks for preds\n",
      "    def chunker(sent):\n",
      "\n",
      "        chunk_reg1 = r\"\"\"\n",
      "                          CHUNK: {(<NN.*><POS>)?<RB>?<JJ.*>*<NN.*>+}\n",
      "                     \"\"\"\n",
      "        chunk_reg2 = r\"\"\"\n",
      "                          CHUNK: {(<JJ.*>|<VB.*>)<XX>}\n",
      "                       \"\"\"\n",
      "        results = []\n",
      "\n",
      "        for chunk_reg in [chunk_reg1, chunk_reg2]:\n",
      "            cp = nltk.RegexpParser(chunk_reg)\n",
      "\n",
      "            tree = cp.parse(sent)\n",
      "            for subtree in tree.subtrees():\n",
      "                if subtree.label() == 'CHUNK':\n",
      "                    results.append(subtree[:])\n",
      "        return results\n",
      "\n",
      "    def human_checker(term_list, top_terms, term_exc):\n",
      "        '''This function loops through the possible terms and\n",
      "        lets human input decide if they actually are or not'''\n",
      "        print 'Are the following terms part of this list: %r?' % (term_list)\n",
      "        if len(top_terms) > 1:\n",
      "            for term in top_terms:\n",
      "                print 'Term: \\x1b[35m %s \\x1b[0m  Count: \\x1b[36m %d \\x1b[0m' % (term[0], (term[1]/7.))\n",
      "                answer_switch = True\n",
      "                while answer_switch:\n",
      "                    add_term = raw_input('Is this similar to %s? (Y, N, exit): ' % (term_list[0]))\n",
      "                    if add_term.lower() == 'y':\n",
      "                        term_list.update(term[0])\n",
      "                        answer_switch = False\n",
      "                    elif add_term.lower() == 'exit':\n",
      "                        #pass switch to exit program\n",
      "                        exit_switch = False\n",
      "                        return term_list, term_exc, exit_switch\n",
      "                    elif add_term.lower() == 'n':\n",
      "                        term_exc.update(term[0])\n",
      "                        answer_switch = False\n",
      "                    else:\n",
      "                        pass\n",
      "                    \n",
      "        exit_switch = False\n",
      "        return term_list, term_exc, exit_switch\n",
      "\n",
      "    def weight_preds(past_predictors, pred_list):\n",
      "        pred_weight_list = []\n",
      "\n",
      "        #create a combined list of all preds, create Counter dict\n",
      "        tot_pred_list = []\n",
      "        for p in past_predictors:\n",
      "            tot_pred_list += p\n",
      "        count_pred = Counter(tot_pred_list)\n",
      "\n",
      "        #add weights to pred terms and create new pred weight lists\n",
      "        for idx in range(len(pred_list)):\n",
      "            weight  = len(past_predictors) - (count_pred[pred_list[idx]]-1)\n",
      "            pred_weight_list.append((pred_list[idx], weight))\n",
      "            \n",
      "        return pred_weight_list\n",
      "\n",
      "\n",
      "    pred_weight_list = weight_preds(past_predictors, pred_list)\n",
      "\n",
      "    top_terms = get_term(data, term_list, term_exc, pred_weight_list)\n",
      "\n",
      "    term_list, term_exc, exit_switch = human_checker(term_list, top_terms, term_exc)\n",
      "    \n",
      "    print 'Active Learning Complete'\n",
      "    return term_list, term_exc, exit_switch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_active_learning(term_list, term_exc, pred_list, pred_exc, engine, concept_id, user_id):\n",
      "    \n",
      "    # get initial terms with word2vec model\n",
      "    term_list, term_exc = choose_more_terms(model, initial_term, term_list, term_exc)\n",
      "    \n",
      "    if concept_id:\n",
      "        new_concept = 1\n",
      "    else:\n",
      "        new_concept = 0\n",
      "        concept_id = str(uuid.uuid4())\n",
      "        \n",
      "    past_predictors = get_past_predictors()\n",
      "    \n",
      "    counter = 0\n",
      "    exit_switch = True\n",
      "    criteria_tracking = []\n",
      "    while exit_switch and counter < 10:\n",
      "        \n",
      "        # load in a random chunk of 10,000 trials\n",
      "        #select a random number between 0-249\n",
      "        while True:\n",
      "            rand_select = random.choice(250)\n",
      "            if rand_select not in criteria_tracking:\n",
      "                criteria_tracking.append(rand_select)\n",
      "                break\n",
      "        \n",
      "        #need to figure out a way to get random sentences from this, rand() is way to slow\n",
      "        result = engine.execute(select(criteria_tagged.c.tagged_text).where(criteria_tagged.c.random_select\n",
      "                                                                            == rand_select))\n",
      "        \n",
      "        #convert into list of lists\n",
      "        data = [eval(r.tagged_text)[0] for r in result]\n",
      "\n",
      "        #mark punctuation with XX tag and convert inner list to tuples for processing\n",
      "        data = [[([0], w[1]) if w[0] not in punctuation else (w[0], 'XX') for w in s] for s in data]\n",
      "\n",
      "        pred_list_new, pred_exc_new, exit_switch = active_learn_predictors(data, term_list, pred_list, pred_exc)\n",
      "        term_list_new, term_exc_new, exit_switch = active_learn_terms(data, term_list, pred_list, term_exc, past_predictors)\n",
      "        \n",
      "        #update the difference in the 4 sets to the database\n",
      "        old = [pred_list, pred_exc, term_list, term_exc]\n",
      "        new = [pred_list_new, pred_exc_new, term_list_new, term_exc_new]\n",
      "        update_type = ['predictor', 'predictor-reject', 'term', 'term-reject']\n",
      "        for ix, s in enumerate(new):\n",
      "            new_values = s.intersection(old[ix])\n",
      "            old[ix] = s\n",
      "            if counter == 0:\n",
      "                update = 'concept-name'\n",
      "            else:\n",
      "                update = update_type[ix]\n",
      "            \n",
      "            #instert data into db\n",
      "            conn.execute(criteria_concept_staging.insert(), [{'user_id': user_id,\n",
      "                                              'concept_id': concept_id,\n",
      "                                              'new_concept': new_concept,\n",
      "                                              'update_type': update,\n",
      "                                              'value':value}\n",
      "                                             for value in new_values])\n",
      "            \n",
      "            print new_values\n",
      "            \n",
      "        counter += 1\n",
      "        \n",
      "    return term_list, pred_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main(initial_term, user_id, concept_id=False):\n",
      "    #initialize the connection to the db\n",
      "    engine = create_engine('mysql+pymysql://' + db_connect.conn)\n",
      "    metadata.create_all(engine)\n",
      "    \n",
      "    #user will select a term and then the term will be run through the word2vec model to come up with similar terms\n",
      "    #if it is an existing concept pull the existing data from db else start from scratch\n",
      "    if concept_id:\n",
      "        term_list = engine.execute(select([concept_terms.c.term]).where(concept_terms.c.concept_id\n",
      "                                                            == concept_id))\n",
      "        term_exc = engine.execute(select([concept_terms_reject.c.term]).where(concept_terms_reject.c.concept_id\n",
      "                                                            == concept_id))\n",
      "        pred_list = engine.execute(select([concept_predictors.c.predictor]).where(concept_predictors.c.concept_id\n",
      "                                                            == concept_id))\n",
      "        pred_exc = engine.execute(select([concept_predictors_reject.c.predictor]).where(concept_predictors_reject.c.concept_id\n",
      "                                                            == concept_id))\n",
      "    else:\n",
      "        term_list = set(initial_term)\n",
      "        term_exc = set()\n",
      "        pred_list = set()\n",
      "        pred_exc = set()\n",
      "\n",
      "\n",
      "    #load in model\n",
      "    model = word2vec.load('data/criteria.bin')\n",
      "    clusters = word2vec.load_clusters('data/criteria-clusters.txt')\n",
      "\n",
      "    # add clusters to model\n",
      "    model.clusters = clusters\n",
      "\n",
      "    term_list, pred_list = run_active_learning(term_list, term_exc, pred_list, pred_exc, engine, concept_id, user_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_term = 'chemotherapy'\n",
      "main(initial_term, 123)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'metadata' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-10-e5c4a2f46f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minitial_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'chemotherapy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-8-4e30d643babf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(initial_term, user_id, concept_id)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#initialize the connection to the db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mysql+pymysql://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdb_connect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#user will select a term and then the term will be run through the word2vec model to come up with similar terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'metadata' is not defined"
       ]
      }
     ],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}