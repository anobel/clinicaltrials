{
 "metadata": {
  "name": "",
  "signature": "sha256:9aee0e47c740d47e3e7435c8d32cc767c0bb65675e4f88cd94ae2081336ba1e9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import cPickle as pickle\n",
      "from collections import Counter\n",
      "from random import shuffle\n",
      "import word2vec\n",
      "import sqlalchemy\n",
      "from sqlalchemy import create_engine\n",
      "from string import punctuation\n",
      "import db_connect"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Initial Concept/Term Selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#user will select a term and then the term will be run through the word2vec model to come up with similar terms\n",
      "\n",
      "initial_term = 'drug'\n",
      "term_list = [initial_term]\n",
      "term_dict = {}\n",
      "pred_list = []\n",
      "pred_dict = {}\n",
      "\n",
      "#load in model\n",
      "model = word2vec.load('data/criteria.bin')\n",
      "clusters = word2vec.load_clusters('data/criteria-clusters.txt')\n",
      "\n",
      "# add clusters to model\n",
      "model.clusters = clusters\n",
      "\n",
      "def get_syn(word):\n",
      "    indexes, metrics = model.cosine(word, n=20)\n",
      "    return model.generate_response(indexes, metrics).tolist()\n",
      "\n",
      "def human_checker_initial(term, syns, term_list, term_dict):\n",
      "    '''This function loops through the possible similar words and\n",
      "    lets human input decide if they actually are or not'''\n",
      "    print 'Are the following terms similar to your term: %r?' % (term)\n",
      "    if len(syns) > 1:\n",
      "        for syn in syns:\n",
      "            print 'Term: \\x1b[35m %s \\x1b[0m  Likelihood: \\x1b[36m %f \\x1b[0m' % (syn[0], syn[1])\n",
      "            answer_switch = True\n",
      "            while answer_switch:\n",
      "                add_term = raw_input('Is this a similar term to %s? (Y, N, exit): ' % (term))\n",
      "                if add_term.lower() == 'y':\n",
      "                    term_list.append(syn[0])\n",
      "                    answer_switch = False\n",
      "                elif add_term.lower() == 'exit':\n",
      "                    #pass switch to exit program\n",
      "                    exit_switch = False\n",
      "                    return term_list, term_dict, exit_switch\n",
      "                elif add_term.lower() == 'n':\n",
      "                    term_dict[syn[0]] = ''\n",
      "                    answer_switch = False\n",
      "                else:\n",
      "                    pass\n",
      "\n",
      "    exit_switch = False\n",
      "    return term_list, term_dict, exit_switch\n",
      "\n",
      "\n",
      "def choose_more_terms(model, initial_term, term_list, term_dict):\n",
      "    #get list of syns\n",
      "    syns = get_syn('drug')\n",
      "    term_list, term_dict, exit_switch = human_checker_initial(term_list[0], syns, term_list, term_dict)\n",
      "    return term_list, term_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_list, term_dict = choose_more_terms(model, initial_term, term_list, term_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Are the following terms similar to your term: 'drug'?\n",
        "Term: \u001b[35m medication \u001b[0m  Likelihood: \u001b[36m 0.764090 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m drugs \u001b[0m  Likelihood: \u001b[36m 0.729234 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_product \u001b[0m  Likelihood: \u001b[36m 0.686553 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m agent \u001b[0m  Likelihood: \u001b[36m 0.669450 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m test_article \u001b[0m  Likelihood: \u001b[36m 0.617005 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m imp \u001b[0m  Likelihood: \u001b[36m 0.615993 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicinal_product \u001b[0m  Likelihood: \u001b[36m 0.604440 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medications \u001b[0m  Likelihood: \u001b[36m 0.601529 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_drug \u001b[0m  Likelihood: \u001b[36m 0.584737 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m vaccine \u001b[0m  Likelihood: \u001b[36m 0.573229 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m prescription_drugs \u001b[0m  Likelihood: \u001b[36m 0.570114 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m compound \u001b[0m  Likelihood: \u001b[36m 0.560294 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m substance \u001b[0m  Likelihood: \u001b[36m 0.552736 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m otc_medications \u001b[0m  Likelihood: \u001b[36m 0.545499 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicinal_products \u001b[0m  Likelihood: \u001b[36m 0.543759 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m product \u001b[0m  Likelihood: \u001b[36m 0.543593 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicines \u001b[0m  Likelihood: \u001b[36m 0.535349 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m ip \u001b[0m  Likelihood: \u001b[36m 0.533222 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m illicit_drug \u001b[0m  Likelihood: \u001b[36m 0.528963 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_compound \u001b[0m  Likelihood: \u001b[36m 0.528536 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Pull in past predictor lists for weighting from db"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#do this here, should be a list of lists\n",
      "past_predictors = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find New Preds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def active_learn_predictors(data, term_list, pred_list, pred_dict):\n",
      "    #look for more predictors for each concept by finding sentnces that have \n",
      "    #concept terms in them and looking for predictors in those sentences \n",
      "\n",
      "    def get_pred(text, term_list, pred_dict, pred_list):\n",
      "        pred_options_dict = Counter()\n",
      "        for sent in text:\n",
      "            #if the sentance has less than 2 words skip it\n",
      "            if len(sent) <= 1:\n",
      "                continue\n",
      "            #crate a sentence rank for judging weight of terms found\n",
      "            sent_rank = 0\n",
      "            for term in term_list:\n",
      "                if term.lower() in ' '.join(zip(*sent)[0]).lower():\n",
      "                    sent_rank += 1\n",
      "            result = chunker(sent)\n",
      "            preds = [' '.join(x) for x in [[x[0] for x in term] for term in result]]\n",
      "            preds.append(' '.join([sent[0][0], sent[1][0]]))\n",
      "            #lower case all preds\n",
      "            preds = [x.lower() for x in preds]\n",
      "            preds = preds * sent_rank\n",
      "            pred_options_dict.update(preds)\n",
      "\n",
      "        #get top 20 predictors that have not been seen before\n",
      "        sorted_preds = sorted(pred_options_dict.items(), key=lambda x: x[1], reverse=True)\n",
      "        counter = 0\n",
      "        top_preds = []\n",
      "        for pred in sorted_preds:\n",
      "            if pred[0] not in pred_list and pred[0] not in pred_dict:\n",
      "                top_preds.append(pred)\n",
      "                counter += 1\n",
      "                if counter == 15 or counter == len(sorted_preds):\n",
      "                    return top_preds\n",
      "        #if there are no preds return empty list\n",
      "        return top_preds\n",
      "\n",
      "    #get chunks for preds\n",
      "    def chunker(sent):\n",
      "\n",
      "        chunk_reg1 = r\"\"\"\n",
      "                          CHUNK: {<NN.*><IN>}\n",
      "                     \"\"\"\n",
      "        chunk_reg2 = r\"\"\"\n",
      "                          CHUNK: {<VB.*><DT>}\n",
      "                     \"\"\"\n",
      "        chunk_reg3 = r\"\"\"\n",
      "                          CHUNK: {<NN.*><VB.*>}\n",
      "                     \"\"\"\n",
      "        results = []\n",
      "\n",
      "        for chunk_reg in [chunk_reg1, chunk_reg2, chunk_reg3]:\n",
      "            cp = nltk.RegexpParser(chunk_reg)\n",
      "\n",
      "            tree = cp.parse(sent)\n",
      "            for subtree in tree.subtrees():\n",
      "                if subtree.label() == 'CHUNK':\n",
      "                    results.append(subtree[:])\n",
      "        return results\n",
      "\n",
      "    def human_checker(term, pred_list, top_preds, pred_dict):\n",
      "        '''This function loops through the possible predictors and\n",
      "        lets human input decide if they actually are or not'''\n",
      "        print 'Are the following predictors of these %r?' % (term)\n",
      "        if len(top_preds) > 1:\n",
      "            for pred in top_preds:\n",
      "                print 'Predictor: \\x1b[35m %s \\x1b[0m  Count: \\x1b[36m %d \\x1b[0m' % (pred[0], pred[1])\n",
      "                answer_switch = True\n",
      "                while answer_switch:\n",
      "                    add_pred = raw_input('Is this a predictor of %s? (Y, N, exit): ' % (term[0]))\n",
      "                    if add_pred.lower() == 'y':\n",
      "                        pred_list.append(pred[0])\n",
      "                        answer_switch = False\n",
      "                    elif add_pred.lower() == 'exit':\n",
      "                        #pass switch to exit program\n",
      "                        exit_switch = False\n",
      "                        return pred_list, pred_dict, exit_switch\n",
      "                    elif add_pred.lower() == 'n':\n",
      "                        pred_dict[pred[0]] = ''\n",
      "                        answer_switch = False\n",
      "                    else:\n",
      "                        pass\n",
      "                    \n",
      "        exit_switch = False\n",
      "        return pred_list, pred_dict, exit_switch\n",
      "\n",
      "\n",
      "    top_preds = get_pred(data, term_list, pred_dict, pred_list)\n",
      "\n",
      "    pred_list, pred_dict, exit_switch = human_checker(term, pred_list, top_preds, pred_dict)\n",
      "    #save list and dict\n",
      "    #make sure it is not null before saving\n",
      "    #****save to db instead****\n",
      "    if pred_list:\n",
      "        pickle.dump(pred_list, open('data/predictor_list.pkl', 'wb'))\n",
      "        pickle.dump(pred_dict, open('data/not_predictor_dict.pkl', 'wb'))\n",
      "    else:\n",
      "        print 'pred list Null'\n",
      " \n",
      "    print 'Active Learning Complete'\n",
      "    return pred_list, pred_dict, exit_switch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find New Terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def active_learn_terms(data, term_list, pred_list, term_dict, past_predictors):\n",
      "    #look for more terms for each concept by finding sentnces that have \n",
      "    #predictors in them and looking for terms in those sentences \n",
      "\n",
      "    def get_pred(text, term_list, term_dict, pred_list):\n",
      "        term_options_dict = Counter()\n",
      "        for sent in text:\n",
      "            for subdoc in doc:\n",
      "                for sent in subdoc:\n",
      "                    #skip sentence if it contains less than one word\n",
      "                    if len(sent) <= 1:\n",
      "                            continue\n",
      "                    #crate a sentence rank for judging weight of terms found\n",
      "                    sent_rank = 0\n",
      "                    for pred in pred_list:\n",
      "                        if pred[0].lower() in ' '.join(zip(*sent)[0]).lower():\n",
      "                            sent_rank += pred[1]\n",
      "                    result = chunker(sent)\n",
      "                    terms = [' '.join(x) for x in [[x[0] for x in term] for term in result]]\n",
      "                    terms.append(' '.join([sent[0][0], sent[1][0]]))\n",
      "                    #lower case all preds\n",
      "                    terms = [x.lower() for x in terms]\n",
      "                    #add weights to terms by multiplying by sent_rank\n",
      "                    terms = terms * sent_rank\n",
      "                    term_options_dict.update(terms)\n",
      "\n",
      "        #get top 20 predictors that have not been seen before\n",
      "        sorted_terms = sorted(term_options_dict.items(), key=lambda x: x[1], reverse=True)\n",
      "        counter = 0\n",
      "        top_terms = []\n",
      "        for term in sorted_terms:\n",
      "            if term[0] not in term_list and term[0] not in term_dict:\n",
      "                top_terms.append(term)\n",
      "                counter += 1\n",
      "                if counter == 15 or counter == len(sorted_terms):\n",
      "                    return top_terms\n",
      "        #if there are no preds return empty list\n",
      "        return top_terms\n",
      "\n",
      "    #get chunks for preds\n",
      "    def chunker(sent):\n",
      "\n",
      "        chunk_reg1 = r\"\"\"\n",
      "                          CHUNK: {(<NN.*><POS>)?<RB>?<JJ.*>*<NN.*>+}\n",
      "                     \"\"\"\n",
      "        chunk_reg2 = r\"\"\"\n",
      "                          CHUNK: {(<JJ.*>|<VB.*>)<XX>}\n",
      "                       \"\"\"\n",
      "        results = []\n",
      "\n",
      "        for chunk_reg in [chunk_reg1, chunk_reg2]:\n",
      "            cp = nltk.RegexpParser(chunk_reg)\n",
      "\n",
      "            tree = cp.parse(sent)\n",
      "            for subtree in tree.subtrees():\n",
      "                if subtree.label() == 'CHUNK':\n",
      "                    results.append(subtree[:])\n",
      "        return results\n",
      "\n",
      "    def human_checker(term_list, top_terms, term_dict):\n",
      "        '''This function loops through the possible terms and\n",
      "        lets human input decide if they actually are or not'''\n",
      "        print 'Are the following terms part of this list: %r?' % (term_list)\n",
      "        if len(top_terms) > 1:\n",
      "            for term in top_terms:\n",
      "                print 'Term: \\x1b[35m %s \\x1b[0m  Count: \\x1b[36m %d \\x1b[0m' % (term[0], (term[1]/7.))\n",
      "                answer_switch = True\n",
      "                while answer_switch:\n",
      "                    add_term = raw_input('Is this similar to %s? (Y, N, exit): ' % (term_list[0]))\n",
      "                    if add_term.lower() == 'y':\n",
      "                        term_list.append(term[0])\n",
      "                        answer_switch = False\n",
      "                    elif add_term.lower() == 'exit':\n",
      "                        #pass switch to exit program\n",
      "                        exit_switch = False\n",
      "                        return term_list, term_dict, exit_switch\n",
      "                    elif add_term.lower() == 'n':\n",
      "                        term_dict[term[0]] = ''\n",
      "                        answer_switch = False\n",
      "                    else:\n",
      "                        pass\n",
      "                    \n",
      "        exit_switch = False\n",
      "        return term_list, term_dict, exit_switch\n",
      "\n",
      "    def weight_preds(past_predictors, pred_list):\n",
      "        pred_weight_list = []\n",
      "\n",
      "        #create a combined list of all preds, create Counter dict\n",
      "        tot_pred_list = []\n",
      "        for p in past_predictors:\n",
      "            tot_pred_list += p\n",
      "        count_pred = Counter(tot_pred_list)\n",
      "\n",
      "        #add weights to pred terms and create new pred weight lists\n",
      "        for idx in range(len(pred_list)):\n",
      "            weight  = len(past_predictors) - (count_pred[pred_list[idx]]-1)\n",
      "            pred_weight_list.append((pred_list[idx], weight))\n",
      "            \n",
      "        return pred_weight_list\n",
      "\n",
      "\n",
      "    pred_weight_list = weight_preds(past_predictors, pred_list)\n",
      "\n",
      "    top_terms = get_pred(data, term, term_dict, pred_weight_list)\n",
      "\n",
      "    term_list, term_dict, exit_switch = human_checker(term_list, top_terms, term_dict)\n",
      "    #save list and dict\n",
      "    #make sure it is not null before saving\n",
      "    if pred_list[idx]:\n",
      "        pickle.dump(term_list, open('data/term_list.pkl', 'wb'))\n",
      "        pickle.dump(term_dict, open('data/not_term_dict.pkl', 'wb'))\n",
      "    else:\n",
      "        print 'Term list Null'\n",
      "    \n",
      "    print 'Active Learning Complete'\n",
      "    return term_list, term_dict, exit_switch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_active_learning(term_list, term_dict, pred_list, pred_dict):\n",
      "    \n",
      "    # load in a random chunk of 10,000 trials\n",
      "    engine = create_engine('mysql+pymysql://' + db_connect.conn)\n",
      "    #need to figure out a way to get random sentences from this, rand() is way to slow\n",
      "    result = engine.execute(\"select tagged_text from criteria_tagged limit 10000\")\n",
      "    \n",
      "    #convert into list of lists\n",
      "    #data = [eval(r.tagged_text)[0] for r in result]\n",
      "    #temp fix for db text limit\n",
      "    data = [eval(r.tagged_text)[0] if r.tagged_text[-3:] == ']]]' else [''] for r in result]\n",
      "    \n",
      "    \n",
      "    #mark punctuation with XX tag\n",
      "    #data = [[[w[0], w[1]] if w[0] not in punctuation else [w[0], 'XX'] for w in s] for s in data]\n",
      "    #temp fix for db text limit\n",
      "    data = [[[w[0], w[1]] if w[0] not in punctuation else [w[0], 'XX'] for w in s] if len(s) > 1 else s for s in data]\n",
      "    \n",
      "    # get initial terms with word2vec model\n",
      "    term_list, term_dict = choose_more_terms(model, initial_term, term_list, term_dict)\n",
      "    \n",
      "    counter = 0\n",
      "    exit_switch = True\n",
      "    while exit_switch and counter < 10:\n",
      "        pred_list, pred_dict, exit_switch = active_learn_predictors(data, term_list, pred_list, pred_dict)\n",
      "        term_list, term_dict, exit_switch = active_learn_terms(data, term_list, pred_list, term_dict, past_predictors)\n",
      "        counter += 1\n",
      "    return term_list, pred_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_list, pred_list = run_active_learning(term_list, term_dict, pred_list, pred_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Are the following terms similar to your term: 'drug'?\n",
        "Term: \u001b[35m medication \u001b[0m  Likelihood: \u001b[36m 0.764090 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m drugs \u001b[0m  Likelihood: \u001b[36m 0.729234 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_product \u001b[0m  Likelihood: \u001b[36m 0.686553 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m agent \u001b[0m  Likelihood: \u001b[36m 0.669450 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m test_article \u001b[0m  Likelihood: \u001b[36m 0.617005 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m imp \u001b[0m  Likelihood: \u001b[36m 0.615993 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicinal_product \u001b[0m  Likelihood: \u001b[36m 0.604440 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medications \u001b[0m  Likelihood: \u001b[36m 0.601529 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_drug \u001b[0m  Likelihood: \u001b[36m 0.584737 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m vaccine \u001b[0m  Likelihood: \u001b[36m 0.573229 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m prescription_drugs \u001b[0m  Likelihood: \u001b[36m 0.570114 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m compound \u001b[0m  Likelihood: \u001b[36m 0.560294 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m substance \u001b[0m  Likelihood: \u001b[36m 0.552736 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m otc_medications \u001b[0m  Likelihood: \u001b[36m 0.545499 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicinal_products \u001b[0m  Likelihood: \u001b[36m 0.543759 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m product \u001b[0m  Likelihood: \u001b[36m 0.543593 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m medicines \u001b[0m  Likelihood: \u001b[36m 0.535349 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m ip \u001b[0m  Likelihood: \u001b[36m 0.533222 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m illicit_drug \u001b[0m  Likelihood: \u001b[36m 0.528963 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term: \u001b[35m investigational_compound \u001b[0m  Likelihood: \u001b[36m 0.528536 \u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Is this a similar term to drug? (Y, N, exit): y\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "chunk structures must contain tagged tokens or trees",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-88c362ebd14e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mterm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_active_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-8-47ac356f1ac1>\u001b[0m in \u001b[0;36mrun_active_learning\u001b[0;34m(term_list, term_dict, pred_list, pred_dict)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mexit_switch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mexit_switch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexit_switch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_learn_predictors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mterm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexit_switch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_learn_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_predictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-6-9b5f1c687818>\u001b[0m in \u001b[0;36mactive_learn_predictors\u001b[0;34m(data, term_list, pred_list, pred_dict)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mtop_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mpred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexit_switch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuman_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-6-9b5f1c687818>\u001b[0m in \u001b[0;36mget_pred\u001b[0;34m(text, term_list, pred_dict, pred_list)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0msent_rank\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-6-9b5f1c687818>\u001b[0m in \u001b[0;36mchunker\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegexpParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msubtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msubtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CHUNK'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/colingerber/Documents/I_School_Final_Project/clinicaltrials/env/lib/python2.7/site-packages/nltk/chunk/regexp.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, chunk_struct, trace)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m                 \u001b[0mchunk_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchunk_struct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/colingerber/Documents/I_School_Final_Project/clinicaltrials/env/lib/python2.7/site-packages/nltk/chunk/regexp.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, chunk_struct, trace)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m         \u001b[0mchunkstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunkString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;31m# Apply the sequence of rules to the chunkstring.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/colingerber/Documents/I_School_Final_Project/clinicaltrials/env/lib/python2.7/site-packages/nltk/chunk/regexp.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, chunk_struct, debug_level)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_struct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pieces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'><'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebug_level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/colingerber/Documents/I_School_Final_Project/clinicaltrials/env/lib/python2.7/site-packages/nltk/chunk/regexp.pyc\u001b[0m in \u001b[0;36m_tag\u001b[0;34m(self, tok)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             raise ValueError('chunk structures must contain tagged '\n\u001b[0m\u001b[1;32m    106\u001b[0m                              'tokens or trees')\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: chunk structures must contain tagged tokens or trees"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "engine = create_engine('mysql+pymysql://clinicaltrials:rgne9d@ischool.berkeley.edu/clinicaltrials')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#need to figure out a way to get random sentences from this, rand() is way to slow\n",
      "result = engine.execute(\"select tagged_text from criteria_tagged limit 10000\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = engine.execute(\"select tagged_text from criteria_tagged limit 10\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = [eval(r.tagged_text)[0] if r.tagged_text[-3:] == ']]]' else '' for r in result]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [[[w[0], w[1]] if w[0] not in punctuation else [w[0], 'XX'] for w in s] for s in result[:3]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}