{
 "metadata": {
  "name": "",
  "signature": "sha256:960a010362198a9a76299cb93d31c330a244800d79f56fae61e5c82a83cb2f7b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import cPickle as pickle\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test data\n",
      "test_data = pickle.load(open('data/test_tagged_data.pkl', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Initial Concept Term Lists"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smoker_list = ['Non-smoker', 'smoker', 'Current smoker', 'smoking', 'tobacco', 'nicotine',\n",
      "               'cigarettes']\n",
      "pregnancy_list = ['Pregnancy']\n",
      "birth_control_list = ['Birth control', 'contraception']\n",
      "drug_list = ['Illicit drugs', 'Alcohol abuse', 'illegal', 'illicit', 'drug abuse']\n",
      "heart_failure_list = ['Congestive Heart Failure', 'heart failure']\n",
      "hiv_list = ['HIV', 'aids', 'human immunodeficiency virus']\n",
      "allergy_list = ['Allergies', 'allergy', 'hypersensitivity']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Inital Predictive Terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smoker_pred_list = ['current']\n",
      "pregnancy_pred_list = ['potential', 'negative']\n",
      "birth_control_pred_list = ['effective', 'Fertile patients', 'must use effective',\n",
      "                           'must use', 'use effective', 'Fertile patients must use',\n",
      "                           'fertile']\n",
      "drug_pred_list = ['use', 'abuse']\n",
      "heart_failure_pred_list = []\n",
      "hiv_pred_list = []\n",
      "allergy_pred_list = ['known', 'history', 'suspected', 'known suspected',\n",
      "                     'clinically significant']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Discount Dictionaries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#dictionaries keeping track of predictors said no to\n",
      "smoker_pred_dict = {}\n",
      "pregnancy_pred_dict = {}\n",
      "birth_control_pred_dict = {}\n",
      "drug_pred_dict = {}\n",
      "heart_failure_pred_dict = {}\n",
      "hiv_pred_dict = {}\n",
      "allergy_pred_dict = {}\n",
      "\n",
      "#dictionaries to keep track of terms said no to\n",
      "smoker_term_dict = {}\n",
      "pregnancy_term_dict = {}\n",
      "birth_control_term_dict = {}\n",
      "drug_term_dict = {}\n",
      "heart_failure_term_dict = {}\n",
      "hiv_term_dict = {}\n",
      "allergy_term_dict = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_list = [smoker_pred_list, pregnancy_pred_list, birth_control_pred_list, drug_pred_list,\n",
      "                   heart_failure_pred_list, hiv_pred_list, allergy_pred_list]\n",
      "term_list = [smoker_list, pregnancy_list, birth_control_list, drug_list, heart_failure_list,\n",
      "             hiv_list, allergy_list]\n",
      "pred_dicts = [smoker_pred_dict, pregnancy_pred_dict, birth_control_pred_dict, drug_pred_dict,\n",
      "              heart_failure_pred_dict, hiv_pred_dict, allergy_pred_dict]\n",
      "term_dicts = [smoker_term_dict, pregnancy_term_dict, birth_control_term_dict, drug_term_dict,\n",
      "              heart_failure_term_dict, hiv_term_dict, allergy_term_dict]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find new predictors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#look for more predictors for each concept by finding sentnces that have \n",
      "#concept terms in them and looking for predictors in those sentences \n",
      "\n",
      "def get_pred(text_dict, term_list, pred_dicts, pred_list):\n",
      "    pred_options_dict = Counter()\n",
      "    for doc in text_dict.values():\n",
      "        for subdoc in doc:\n",
      "            for sent in subdoc:\n",
      "                for term in term_list:\n",
      "                    if term.lower() in ' '.join(zip(*sent)[0]).lower():\n",
      "                        if len(sent) > 1:\n",
      "                            result = chunker(sent)\n",
      "                            preds = [' '.join([x[0], y[0]]) for x,y in result]\n",
      "                            preds.append(' '.join([sent[0][0], sent[1][0]]))\n",
      "                            #lower case all preds\n",
      "                            preds = [x.lower() for x in preds]\n",
      "                            pred_options_dict.update(preds)\n",
      "                        break\n",
      "    \n",
      "    #get top 20 predictors that have not been seen before\n",
      "    sorted_preds = sorted(pred_options_dict.items(), key=lambda x: x[1], reverse=True)\n",
      "    counter = 0\n",
      "    top_preds = []\n",
      "    for pred in sorted_preds:\n",
      "        if pred[0] not in pred_list and pred[0] not in pred_dicts:\n",
      "            top_preds.append(pred)\n",
      "            counter += 1\n",
      "            if counter == 20 or counter == len(sorted_preds):\n",
      "                return top_preds\n",
      "    #if there are no preds return empty list\n",
      "    return top_preds\n",
      "                        \n",
      "#get chunks for preds\n",
      "def chunker(sent):\n",
      "    \n",
      "    chunk_reg1 = r\"\"\"\n",
      "                      CHUNK: {<NN.*><IN>}\n",
      "                 \"\"\"\n",
      "    chunk_reg2 = r\"\"\"\n",
      "                      CHUNK: {<VB.*><DT>}\n",
      "                 \"\"\"\n",
      "    chunk_reg3 = r\"\"\"\n",
      "                      CHUNK: {<NN.*><VB.*>}\n",
      "                 \"\"\"\n",
      "    results = []\n",
      "    \n",
      "    for chunk_reg in [chunk_reg1, chunk_reg2, chunk_reg3]:\n",
      "        cp = nltk.RegexpParser(chunk_reg)\n",
      "\n",
      "        tree = cp.parse(sent)\n",
      "        for subtree in tree.subtrees():\n",
      "            if subtree.label() == 'CHUNK':\n",
      "                results.append(subtree[:])\n",
      "    return results\n",
      "\n",
      "def human_checker(term, pred_list, top_preds, pred_dict):\n",
      "    '''This function loops through the possible predictors and\n",
      "    lets human input decide if they actually are or not'''\n",
      "    print 'Are the following predictors of these %r?' % (term)\n",
      "    if len(top_preds) > 1:\n",
      "        for pred in top_preds:\n",
      "            print 'Predictor: \\x1b[35m %s \\x1b[0m  Count: \\x1b[36m %d \\x1b[0m' % (pred[0], pred[1])\n",
      "            add_pred = raw_input('Is this a predictor of %s? (Y, N): ' % (term[0]))\n",
      "            if add_pred.lower() == 'y':\n",
      "                pred_list.append(pred[0])\n",
      "            else:\n",
      "                pred_dict[pred[0]] = ''\n",
      "                \n",
      "    return pred_list, pred_dict\n",
      "            \n",
      "                        \n",
      "for idx, term in enumerate(term_list):\n",
      "    top_preds = get_pred(test_data, term, pred_dicts[idx], pred_list[idx])\n",
      "    print '\\n**NEW Concept**\\n'\n",
      "    pred_list[idx], pred_dicts[idx] = human_checker(term, pred_list[idx], top_preds, pred_dicts[idx])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "**NEW Concept**\n",
        "\n",
        "Are the following predictors of these ['Non-smoker', 'smoker', 'Current smoker', 'smoking', 'tobacco', 'nicotine', 'cigarettes']?\n",
        "\n",
        "**NEW Concept**\n",
        "\n",
        "Are the following predictors of these ['Pregnancy']?\n",
        "\n",
        "**NEW Concept**\n",
        "\n",
        "Are the following predictors of these ['Birth control', 'contraception']?\n",
        "\n",
        "**NEW Concept**\n",
        "\n",
        "Are the following predictors of these ['Illicit drugs', 'Alcohol abuse', 'illegal', 'illicit', 'drug abuse']?\n",
        "\n",
        "**NEW Concept**\n",
        "\n",
        "Are the following predictors of these ['Congestive Heart Failure', 'heart failure']?\n",
        "\n",
        "**NEW Concept**\n",
        "\n",
        "Are the following predictors of these ['HIV', 'aids', 'human immunodeficiency virus']?\n",
        "\n",
        "**NEW Concept**\n",
        "\n",
        "Are the following predictors of these ['Allergies', 'allergy', 'hypersensitivity']?\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find new terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#look for more terms for each concept by finding sentnces that have \n",
      "#predictors in them and looking for terms in those sentences \n",
      "\n",
      "def get_pred(text_dict, term_list, term_dicts, pred_list):\n",
      "    term_options_dict = Counter()\n",
      "    for doc in text_dict.values():\n",
      "        for subdoc in doc:\n",
      "            for sent in subdoc:\n",
      "                for pred in pred_list:\n",
      "                    if pred.lower() in ' '.join(zip(*sent)[0]).lower():\n",
      "                        if len(sent) > 1:\n",
      "                            result = chunker(sent)\n",
      "                            terms = [' '.join([x[0], y[0]]) for x,y in result]\n",
      "                            terms.append(' '.join([sent[0][0], sent[1][0]]))\n",
      "                            #lower case all preds\n",
      "                            terms = [x.lower() for x in preds]\n",
      "                            term_options_dict.update(terms)\n",
      "                        break\n",
      "    \n",
      "    #get top 20 predictors that have not been seen before\n",
      "    sorted_terms = sorted(term_options_dict.items(), key=lambda x: x[1], reverse=True)\n",
      "    counter = 0\n",
      "    top_terms = []\n",
      "    for term in sorted_terms:\n",
      "        if term[0] not in term_list and term[0] not in term_dicts:\n",
      "            top_terms.append(term)\n",
      "            counter += 1\n",
      "            if counter == 20 or counter == len(sorted_terms):\n",
      "                return top_terms\n",
      "    #if there are no preds return empty list\n",
      "    return top_terms\n",
      "                        \n",
      "#get chunks for preds\n",
      "def chunker(sent):\n",
      "    \n",
      "    chunk_reg1 = r\"\"\"\n",
      "                      CHUNK: {(<NN.*><POS>)?<RB>?<JJ.*>*<NN.*>+}\n",
      "                 \"\"\"\n",
      "#     chunk_reg2 = r\"\"\"\n",
      "#                       CHUNK: {<VB.*><DT>}\n",
      "#                  \"\"\"\n",
      "#     chunk_reg3 = r\"\"\"\n",
      "#                       CHUNK: {<NN.*><VB.*>}\n",
      "#                  \"\"\"\n",
      "    results = []\n",
      "    \n",
      "    for chunk_reg in [chunk_reg1]:\n",
      "        cp = nltk.RegexpParser(chunk_reg)\n",
      "\n",
      "        tree = cp.parse(sent)\n",
      "        for subtree in tree.subtrees():\n",
      "            if subtree.label() == 'CHUNK':\n",
      "                results.append(subtree[:])\n",
      "    return results\n",
      "\n",
      "def human_checker(term_list, top_terms, term_dict):\n",
      "    '''This function loops through the possible terms and\n",
      "    lets human input decide if they actually are or not'''\n",
      "    print 'Are the following terms part of this list: %r?' % (term)\n",
      "    if len(top_terms) > 1:\n",
      "        for term in top_terms:\n",
      "            print 'Term: \\x1b[35m %s \\x1b[0m  Count: \\x1b[36m %d \\x1b[0m' % (term[0], term[1])\n",
      "            add_term = raw_input('Is this similar to %s? (Y, N): ' % (term_list[0]))\n",
      "            if add_term.lower() == 'y':\n",
      "                term_list.append(term[0])\n",
      "            else:\n",
      "                term_dict[term[0]] = ''\n",
      "                \n",
      "    return term_list, term_dict\n",
      "            \n",
      "                        \n",
      "for idx, term in enumerate(term_list):\n",
      "    top_terms = get_pred(test_data, term, term_dicts[idx], pred_list[idx])\n",
      "    print '\\n**NEW Concept**\\n'\n",
      "    term_list[idx], term_dicts[idx] = human_checker(term, top_terms, term_dicts[idx])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Weighting\n",
      "\n",
      "###Finding Pred terms\n",
      "\n",
      "Weight preds in sentences more if there are more terms in the sentence\n",
      "\n",
      "###Terms\n",
      "\n",
      "Lower weight for every extra time a pred term is in another pred list"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}