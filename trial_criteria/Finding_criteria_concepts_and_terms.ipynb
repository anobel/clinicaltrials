{
 "metadata": {
  "name": "",
  "signature": "sha256:889f33b303947f261e42b62159ac31d6031251aa0ffe254ee5ed718602d6206d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import nltk\n",
      "import codecs\n",
      "import unicodedata\n",
      "import re\n",
      "from copy import deepcopy\n",
      "from pyUtil import easyPickle as pickle\n",
      "from pyUtil import flattenList as flatten"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/colingerber/anaconda/lib/python2.7/site-packages/pytz-2013b-py2.7.egg/pytz/__init__.py:35: UserWarning: Module argparse was already imported from /Users/colingerber/anaconda/lib/python2.7/argparse.pyc, but /Users/colingerber/anaconda/lib/python2.7/site-packages is being added to sys.path\n",
        "  from pkg_resources import resource_stream\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data Input"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "criteria_text = codecs.open('Data/ct_criteria_colin.txt',\n",
      "                            encoding=\"utf-8\")\n",
      "criteria_text = criteria_text.readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Chunck sentences and tokens"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#break sentences on '-'\n",
      "criteria_text_sent = [re.split(' - ', line) for line in criteria_text]\n",
      "\n",
      "#get sentence tokenizer\n",
      "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "\n",
      "#run the sentence tokenizer over all the documents\n",
      "def sent_token(text):\n",
      "    sentence_groups = []\n",
      "    for sent_group in text:\n",
      "        group_holder = []\n",
      "        for sent in sent_group:\n",
      "            group_holder.append(sent_tokenizer.tokenize(sent))\n",
      "        sentence_groups.append(group_holder)\n",
      "        del group_holder\n",
      "    return sentence_groups\n",
      "\n",
      "criteria_text_sent = sent_token(criteria_text_sent)\n",
      "\n",
      "\n",
      "#Flatten the documents to contain just a list of strings where each string is a sentence\n",
      "def flatten_docs(text):\n",
      "    result = []\n",
      "    for doc in text:\n",
      "        result.append(flatten.flatten(doc))\n",
      "    return result\n",
      "\n",
      "criteria_text_docs = flatten_docs(criteria_text_sent)\n",
      "\n",
      "#create a list of all sentences\n",
      "criteria_text_sents = flatten.flatten(criteria_text_docs)\n",
      "\n",
      "#CREATING TOKENS\n",
      "\n",
      "#patter for tokenizing\n",
      "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
      "        ([A-Z]\\.)+        # abbreviations, e.g. U.S.A\n",
      "        | \\w+([-\u2018]\\w+)*        # words with optional internal hyphens\n",
      "        | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
      "        | \\.\\.\\.            # ellipsis...   \n",
      "        | [][.,;\"'?():\\-_`]+  # these are separate tokens\n",
      "        '''\n",
      "#create tokens for the sentence list\n",
      "criteria_text_sent_tokens = [nltk.regexp_tokenize(sent, pattern) for sent\n",
      "                         in criteria_text_sents]\n",
      "\n",
      "#use this for creating tokens for the documents\n",
      "def doc_token(text):\n",
      "    result = []\n",
      "    for doc in text:\n",
      "        doc_text = []\n",
      "        for sent in doc:\n",
      "            doc_text.append(nltk.regexp_tokenize(sent, pattern))\n",
      "        result.append(doc_text)\n",
      "    return result\n",
      "#criteria_text_docs_token = doc_token(criteria_text_docs)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Tag tokens"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tag document structured criteria text\n",
      "def doc_tagger_pos(text):\n",
      "    result = []\n",
      "    for doc in text:\n",
      "        doc_text = []\n",
      "        for sent in doc:\n",
      "            doc_text.append(nltk.pos_tag(sent))\n",
      "        result.append(doc_text)\n",
      "    return result\n",
      "\n",
      "#criteria_text_docs_tagged_pos = doc_tagger_pos(criteria_text_docs_token)\n",
      "\n",
      "#tag sentence structured criteria text\n",
      "criteria_text_sent_tag = []\n",
      "for sent in criteria_text_sent_tokens:\n",
      "    criteria_text_sent_tag.append(nltk.pos_tag(sent))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Save and load tagged corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save tagged corpus\n",
      "pickle.save_object(criteria_text_sent_tag,\n",
      "                   'criteria_corpus_pos_tagged.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load tagged corpus\n",
      "criteria_text_sent_tag = pickle.load_object('criteria_corpus_pos_tagged.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Keyphrases for criteria"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Ngrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#imports\n",
      "from nltk.util import ngrams\n",
      "from nltk import FreqDist\n",
      "import string\n",
      "from nltk.corpus import stopwords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#remove stopwords and punctuation\n",
      "def remove_punct(text):\n",
      "    return [[word for word in sent if word[0] not in string.punctuation] for sent in text]\n",
      "def remove_stop(text):\n",
      "    return [[word for word in sent if word.lower() not in stopwords.words('english')] for sent in text]\n",
      "\n",
      "#use non-tagged corpus\n",
      "\n",
      "criteria_sents_no_stop = remove_punct(criteria_text_sent_tokens)\n",
      "criteria_sents_no_stop = remove_stop(criteria_sents_no_stop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def multinNgram(n, text):\n",
      "    '''This funciton loops through ngrams of length 1 to n.'''\n",
      "    result = {}\n",
      "    flat_list = flatten.flatten(text)\n",
      "    for num in range(n, 0, -1):\n",
      "        result[num] = []\n",
      "        ngram = ngrams(flat_list, num)\n",
      "        result[num] = [' '.join(gram) for gram in ngram]\n",
      "    return result\n",
      "\n",
      "multiGrams = multinNgram(4, criteria_sents_no_stop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ngram in multiGrams:\n",
      "    print FreqDist(multiGrams[ngram]).most_common(40)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'study', 5050), (u'Criteria', 3572), (u'1', 3491), (u'within', 3429), (u'prior', 3306), (u'2', 3110), (u'disease', 3062), (u'Patients', 2775), (u'3', 2638), (u'must', 2295), (u'5', 2243), (u'months', 2230), (u'therapy', 2061), (u'years', 2028), (u'treatment', 1990), (u'least', 1950), (u'history', 1875), (u'Inclusion', 1853), (u'\\xe2', 1850), (u'Exclusion', 1811), (u'days', 1752), (u'6', 1723), (u'4', 1707), (u'weeks', 1571), (u'use', 1333), (u'consent', 1328), (u'patients', 1287), (u'drug', 1233), (u'History', 1172), (u'18', 1119), (u'e', 1103), (u'g', 1068), (u'including', 1047), (u'informed', 1047), (u'patient', 1037), (u'significant', 995), (u'screening', 993), (u'Subjects', 957), (u'age', 951), (u'greater', 947)]\n",
        "[(u'Inclusion Criteria', 1770), (u'Exclusion Criteria', 1725), (u'informed consent', 1004), (u'e g', 792), (u'6 months', 765), (u'3 months', 692), (u'30 days', 599), (u'Criteria 1', 598), (u'18 years', 564), (u'days prior', 561), (u'4 weeks', 546), (u'years age', 509), (u'1 5', 455), (u'upper limit', 435), (u'pregnancy test', 430), (u'study entry', 430), (u'prior study', 429), (u'limit normal', 426), (u'months prior', 402), (u'weeks prior', 402), (u'within past', 397), (u'Patients must', 385), (u'clinically significant', 379), (u'childbearing potential', 349), (u'study drug', 340), (u'mg dL', 336), (u'written informed', 333), (u'within 30', 332), (u'heart failure', 318), (u'12 months', 300), (u'Criteria Patients', 280), (u'within last', 277), (u'\\xe2 1', 273), (u'birth control', 273), (u'least one', 262), (u'within 6', 262), (u'5 x', 260), (u'5 years', 259), (u'2 5', 254), (u'\\xe2 2', 246)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(u'upper limit normal', 396), (u'written informed consent', 328), (u'within 30 days', 326), (u'Exclusion Criteria 1', 304), (u'Inclusion Criteria 1', 291), (u'18 years age', 221), (u'prior study entry', 214), (u'within 6 months', 211), (u'within 4 weeks', 205), (u'30 days prior', 194), (u'congestive heart failure', 193), (u'times upper limit', 182), (u'4 weeks prior', 164), (u'within 3 months', 163), (u'consent Exclusion Criteria', 159), (u'ECOG performance status', 152), (u'6 months prior', 147), (u'1 5 x', 142), (u'Exclusion Criteria Patients', 141), (u'Inclusion Criteria Patients', 138), (u'5 x ULN', 137), (u'3 months prior', 135), (u'weeks since prior', 135), (u'informed consent Exclusion', 134), (u'within 14 days', 125), (u'limit normal ULN', 122), (u'study Inclusion Criteria', 121), (u'least 3 months', 120), (u'least 4 weeks', 116), (u'first dose study', 115), (u'PRIOR CONCURRENT THERAPY', 114), (u'within 7 days', 114), (u'prior first dose', 113), (u'childbearing potential must', 110), (u'\\xe2 1 5', 110), (u'method birth control', 110), (u'least 6 months', 106), (u'past 6 months', 106), (u'study Exclusion Criteria', 106), (u'5 times upper', 106)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(u'times upper limit normal', 164), (u'within 30 days prior', 135), (u'informed consent Exclusion Criteria', 129), (u'upper limit normal ULN', 121), (u'within 4 weeks prior', 95), (u'5 times upper limit', 94), (u'New York Heart Association', 85), (u'provide written informed consent', 85), (u'patients must use effective', 82), (u'Fertile patients must use', 81), (u'must use effective contraception', 80), (u'within 6 months prior', 75), (u'4 weeks since prior', 75), (u'x upper limit normal', 75), (u'human immunodeficiency virus HIV', 75), (u'Eastern Cooperative Oncology Group', 74), (u'within past 6 months', 73), (u'Inclusion Criteria Male female', 70), (u'1 5 mg dL', 70), (u'PRIOR CONCURRENT THERAPY Biologic', 69), (u'within 3 months prior', 67), (u'prior first dose study', 67), (u'CONCURRENT THERAPY Biologic therapy', 67), (u'Cooperative Oncology Group ECOG', 66), (u'1 5 x ULN', 63), (u'18 years age older', 63), (u'within 14 days prior', 62), (u'childbearing potential must negative', 59), (u'nursing Negative pregnancy test', 59), (u'pregnant nursing Negative pregnancy', 59), (u'within 7 days prior', 58), (u'pregnancy test Fertile patients', 58), (u'test Fertile patients must', 58), (u'Negative pregnancy test Fertile', 57), (u'least 4 weeks since', 54), (u'days prior first dose', 54), (u'5 x upper limit', 53), (u'\\xe2 1 5 x', 52), (u'PATIENT CHARACTERISTICS Age 18', 52), (u'within 28 days prior', 51)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Chunker and Verbs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get the verbs out\n",
      "#verbs = [word for word in criteria_text_sent_tag if word[1].startswith('V')]\n",
      "\n",
      "#freqdist of verbs\n",
      "#fd_verbs = FreqDist(verbs)\n",
      "\n",
      "#top 10 most common\n",
      "#[word[0][0] for word in fd_verbs.most_common(10)]\n",
      "\n",
      "#get specific sents containing certain words\n",
      "def get_specific_sent(text, spec_words):\n",
      "\n",
      "    specific_sents = []\n",
      "    for sent in text:\n",
      "        for word in sent:\n",
      "            if word[0].lower() in spec_words:\n",
      "                specific_sents.append(sent)\n",
      "                break\n",
      "    return specific_sents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create subsection of sentences to run the chunker on that contain cerain phrases\n",
      "drug_terms = ['drug', 'alcohol', 'abuse', 'illegal', 'illicit']\n",
      "drug_sents = get_specific_sent(criteria_text_sent_tag, drug_terms)\n",
      "allergy_terms = ['allergy', 'allergies']\n",
      "allergy_sents = get_specific_sent(criteria_text_sent_tag, allergy_terms)\n",
      "fertile_terms = ['fertile']\n",
      "fertile_sents = get_specific_sent(criteria_text_sent_tag, fertile_terms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get chunks\n",
      "def chunker(tagged_corpus, chunk_reg):\n",
      "    \n",
      "    cp = nltk.RegexpParser(chunk_reg)\n",
      "    \n",
      "    results = []\n",
      "    \n",
      "    for sents in tagged_corpus:\n",
      "        tree = cp.parse(sents)\n",
      "        for subtree in tree.subtrees():\n",
      "            if subtree.label() == 'CHUNK':\n",
      "                results.append(subtree[:])\n",
      "    return results\n",
      "\n",
      "chunk_reg = r\"\"\"\n",
      "                  CHUNK: {(<NN.*><POS>)?<RB>?<JJ.*>*<NN.*>+}\n",
      "             \"\"\"\n",
      "\n",
      "\n",
      "def get_doc_desc(num, terms, text):\n",
      "    print 'For terms: ' + ', '.join(terms)\n",
      "    for sent in [[word[0] for word in sent] for sent in text[:10]]:\n",
      "        print ' '.join(sent)\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunks_dict_criteria = chunker(drug_sents, chunk_reg)\n",
      "get_doc_desc(10, drug_terms, chunks_dict_criteria)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For terms: drug, alcohol, abuse, illegal, illicit\n",
        "medications\n",
        "study drug\n",
        "duration\n",
        "study\n",
        "Known history\n",
        "alcohol abuse\n",
        "illicit drugs\n",
        "steroids\n",
        "alcoholic beverages day\n",
        "Participation\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunks_dict_criteria = chunker(allergy_sents, chunk_reg)\n",
      "get_doc_desc(10, allergy_terms, chunks_dict_criteria)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For terms: allergy, allergies\n",
        "eruptions\n",
        "drug allergies\n",
        "food allergy\n",
        "eczema\n",
        "psoriasis\n",
        "urticaria\n",
        "opinion\n",
        "investigator\n",
        "contraindication\n",
        "study enrollment\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#look at multigrams as well for the specific sentences\n",
      "def multinNgram(n, text):\n",
      "    '''This funciton loops through ngrams of length 1 to n.'''\n",
      "    text = remove_punct(text)\n",
      "    text = remove_stop(text)\n",
      "    result = {}\n",
      "    flat_list = flatten.flatten(text)\n",
      "    for num in range(n, 0, -1):\n",
      "        result[num] = []\n",
      "        ngram = ngrams(flat_list, num)\n",
      "        result[num] = [' '.join(gram) for gram in ngram]\n",
      "    return result\n",
      "\n",
      "def get_top_mulitgrams(multiGrams, terms, num):\n",
      "    print 'For terms: ' + ', '.join(terms)\n",
      "    for ngram in multiGrams:\n",
      "        fd = FreqDist(multiGrams[ngram]).most_common(num)\n",
      "        for key in fd:\n",
      "            print key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multiGrams = multinNgram(4, [[word[0] for word in sent] for sent in allergy_sents])\n",
      "get_top_mulitgrams(multiGrams, allergy_terms, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For terms: allergy, allergies\n",
        "(u'allergy', 272)\n",
        "(u'history', 97)\n",
        "(u'allergies', 76)\n",
        "(u'Known', 71)\n",
        "(u'known', 66)\n",
        "(u'study', 62)\n",
        "(u'Allergy', 61)\n",
        "(u'hypersensitivity', 59)\n",
        "(u'drug', 57)\n",
        "(u'History', 46)\n",
        "(u'Known allergy', 43)\n",
        "(u'known allergy', 28)\n",
        "(u'history allergy', 27)\n",
        "(u'allergy hypersensitivity', 23)\n",
        "(u'drug allergy', 18)\n",
        "(u'suspected allergy', 15)\n",
        "(u'History allergy', 14)\n",
        "(u'allergy study', 13)\n",
        "(u'clinically significant', 13)\n",
        "(u'allergy intolerance', 12)\n",
        "(u'history drug allergy', 10)\n",
        "(u'Known suspected allergy', 8)\n",
        "(u'history allergy hypersensitivity', 7)\n",
        "(u'known suspected allergy', 7)\n",
        "(u'allergy study medications', 6)\n",
        "(u'history clinically significant', 6)\n",
        "(u'Known allergy sensitivity', 5)\n",
        "(u'PRIOR CONCURRENT THERAPY', 5)\n",
        "(u'CONCURRENT THERAPY Biologic', 4)\n",
        "(u'medications components thereof', 4)\n",
        "(u'components thereof history drug', 4)\n",
        "(u'history drug allergy opinion', 4)\n",
        "(u'sensitivity study medications components', 4)\n",
        "(u'History sensitivity study medications', 4)\n",
        "(u'medications components thereof history', 4)\n",
        "(u'thereof history drug allergy', 4)\n",
        "(u'PRIOR CONCURRENT THERAPY Biologic', 4)\n",
        "(u'CONCURRENT THERAPY Biologic therapy', 4)\n",
        "(u'study medications components thereof', 4)\n",
        "(u'1 5 mg dL', 3)\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multiGrams = multinNgram(4, [[word[0] for word in sent] for sent in fertile_sents])\n",
      "get_top_mulitgrams(multiGrams, fertile_terms, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For terms: fertile\n",
        "(u'contraception', 101)\n",
        "(u'use', 100)\n",
        "(u'patients', 95)\n",
        "(u'effective', 92)\n",
        "(u'must', 91)\n",
        "(u'Fertile', 88)\n",
        "(u'least', 63)\n",
        "(u'therapy', 55)\n",
        "(u'study', 53)\n",
        "(u'prior', 47)\n",
        "(u'use effective', 88)\n",
        "(u'patients must', 84)\n",
        "(u'must use', 84)\n",
        "(u'Fertile patients', 82)\n",
        "(u'effective contraception', 76)\n",
        "(u'PRIOR CONCURRENT', 29)\n",
        "(u'CONCURRENT THERAPY', 29)\n",
        "(u'contraception Fertile', 29)\n",
        "(u'Biologic therapy', 25)\n",
        "(u'THERAPY Biologic', 25)\n",
        "(u'patients must use', 83)\n",
        "(u'must use effective', 82)\n",
        "(u'Fertile patients must', 81)\n",
        "(u'use effective contraception', 75)\n",
        "(u'PRIOR CONCURRENT THERAPY', 29)\n",
        "(u'contraception Fertile patients', 28)\n",
        "(u'effective contraception Fertile', 26)\n",
        "(u'CONCURRENT THERAPY Biologic', 25)\n",
        "(u'THERAPY Biologic therapy', 24)\n",
        "(u'contraception PRIOR CONCURRENT', 15)\n",
        "(u'patients must use effective', 82)\n",
        "(u'Fertile patients must use', 81)\n",
        "(u'must use effective contraception', 74)\n",
        "(u'contraception Fertile patients must', 28)\n",
        "(u'use effective contraception Fertile', 26)\n",
        "(u'effective contraception Fertile patients', 25)\n",
        "(u'PRIOR CONCURRENT THERAPY Biologic', 25)\n",
        "(u'CONCURRENT THERAPY Biologic therapy', 24)\n",
        "(u'contraception PRIOR CONCURRENT THERAPY', 15)\n",
        "(u'use effective contraception PRIOR', 15)\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_sents(text):\n",
      "    for sent in text:\n",
      "        print ' '.join([word[0] for word in sent])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_sents(fertile_sents[:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fertile patients must use effective contraception PRIOR CONCURRENT THERAPY : Biologic therapy\n",
        "Fertile patients must use effective contraception PRIOR CONCURRENT THERAPY : Biologic therapy :\n",
        "Fertile patients must use effective contraception during and for 4 weeks after study participation\n",
        "Fertile patients must use effective contraception PRIOR CONCURRENT THERAPY : Biologic therapy :\n",
        "Agreement to use a condom , and with a fertile female partner , another form of contraception .\n",
        "DISEASE CHARACTERISTICS : Histologically proven epithelial adenocarcinoma of the ovary , fallopian tube , or peritoneum CA 125 greater than 35 U mL No conclusive radiological or clinical evidence of disease No disease recurrence Must have received only 1 prior platinum based chemotherapy regimen No tumors of low malignant potential or noninvasive disease PATIENT CHARACTERISTICS : Age : 18 and over Performance status : ECOG 0-2 Life expectancy : At least 6 months Hematopoietic : Hemoglobin at least 8 . 0 g dL Lymphocyte count at least 1 , 000 mm3 Neutrophil count at least 1 , 500 mm3 Platelet count at least 100 , 000 mm3 Hepatic : Bilirubin no greater than 1 . 5 times normal Renal : Creatinine no greater than 2 mg dL Cardiovascular : No uncontrolled hypertension No congestive heart failure No arrhythmias Other : Not pregnant or nursing Negative pregnancy test Fertile patients must use effective contraception No active autoimmune disease requiring chronic treatment No allergy to murine proteins No documented anaphylactic reaction to any drug No active infection causing fever No immunodeficiency disease No uncontrolled nonmalignant diseases No other malignancy ( except nonmelanomatous skin cancer or carcinoma in situ of the cervix ) unless curatively treated and free of disease for at least 5 years PRIOR CONCURRENT THERAPY : Biologic therapy : No prior murine monoclonal antibodies Chemotherapy : See Disease Characteristics At least 4 weeks since prior platinum based chemotherapy No concurrent chemotherapy Endocrine therapy : Not specified Radiotherapy : At least 6 months since prior limited field ( i . e ., abdominal or pelvic ) radiotherapy No prior whole abdominal radiotherapy Surgery : At least 4 weeks since prior surgery No prior splenectomy Other : At least 4 weeks since prior immunosuppressive drugs No concurrent immunosuppressive drugs At least 30 days since other prior investigational drugs\n",
        "Patients who are fertile must agree to use an effective method of contraception during participation in the study\n",
        "Fertile patients must use effective contraception PRIOR CONCURRENT THERAPY : Biologic therapy :\n",
        "Fertile patients must use effective contraception\n",
        "Fertile patients must use effective barrier contraception during and for 3 months after study\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}